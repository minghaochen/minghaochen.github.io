<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>‘科研’ on MH&#39;s Blog</title>
    <link>https://minghaochen.github.io/categories/%E7%A7%91%E7%A0%94/</link>
    <description>Recent content in ‘科研’ on MH&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 10 May 2020 09:16:56 +0800</lastBuildDate>
    
	<atom:link href="https://minghaochen.github.io/categories/%E7%A7%91%E7%A0%94/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>「模型预测控制」简要概念</title>
      <link>https://minghaochen.github.io/post/%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6%E7%AE%80%E8%A6%81%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Sun, 10 May 2020 09:16:56 +0800</pubDate>
      
      <guid>https://minghaochen.github.io/post/%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6%E7%AE%80%E8%A6%81%E6%A6%82%E5%BF%B5/</guid>
      <description>&lt;h1 id=&#34;基本概念&#34;&gt;基本概念&lt;/h1&gt;

&lt;p&gt;为什么采用MPC？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;处理多变量耦合&lt;/li&gt;
&lt;li&gt;处理输入状态约束&lt;/li&gt;
&lt;li&gt;卡边控制 (意味着更高的经济效益)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;应用：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;尿素装置合成段的控制&lt;/li&gt;
&lt;li&gt;在各种石化和化工厂中&lt;/li&gt;
&lt;li&gt;食品加工&lt;/li&gt;
&lt;li&gt;机电系统&lt;/li&gt;
&lt;li&gt;暖通空调系统(楼宇控制)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MPC的种类：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;线性模型：$x(k+1)=Ax(k)+Bu(k)$，一般为凸优化问题。由于线性MPC包含约束的处理，因此是一种非线性控制策略。&lt;/li&gt;
&lt;li&gt;非线性模型：$x(k+1)=f(x(k),u(k))$，一般为非凸优化问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;线性MPC优化命题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;目标函数：状态跟踪 $x_{ref}$，输入跟踪 $u_{ref}$&lt;/li&gt;
&lt;li&gt;约束：模型、输入约束、状态约束&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MPC算法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;读取当前状态 $x(k)$&lt;/li&gt;
&lt;li&gt;计算最优控制序列&lt;/li&gt;
&lt;li&gt;实施序列的第一个元素（多变量是向量）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;LQR和MPC：当预测时域趋于无穷且忽略约束时，MPC等价于LQR。&lt;/p&gt;

&lt;p&gt;常规的MPC优化命题可以写为一个LCQP（线性约束二次规划），优化变量可以是$N*(n_x+n_u)$个（模型当作约束）或者$N*n_u$个（状态用输入和模型表示）。&lt;/p&gt;

&lt;p&gt;带有 terminal cost 的MPC：
目标函数中多加入对 $x(k+N)$ 的惩罚，用于保证稳定性。&lt;/p&gt;

&lt;p&gt;可以通过求解离散时间Riccati方程来得到终端代价矩阵：&lt;/p&gt;

&lt;p&gt;$$
A^TSA-S-(A^TSB)(B^TSB+R)^{-1}(B^TSA)+Q=0
$$
其中 $u(k)=-Kx(k)$为稳定控制率，$K=(B^TSB+R)^{-1}(B^TSA)$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[K,S]=dlqr(A,B,Q,R)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;MPC的历史&lt;/p&gt;

&lt;p&gt;1st  generation MPC：IDCOM (Richalet et al., 1976) 、 DMC (Shell, 1973)&lt;/p&gt;

&lt;p&gt;2nd  generation MPC：QDMC (Shell, 1983)&lt;/p&gt;

&lt;p&gt;3rd  generation MPC：IDCOM-M (Setpoint, 1988), SMOC (Shell, late 80’s)&lt;/p&gt;

&lt;p&gt;4th  generation MPC： DMC-Plus (Honeywell Hi-Spec, ‘95), RMPCT (Aspen Tech, ‘96)&lt;/p&gt;

&lt;p&gt;3种不同的formulation：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;无穷时域、无约束、显式解&lt;/li&gt;
&lt;li&gt;有限时域、有约束、无显式解&lt;/li&gt;
&lt;li&gt;无限时域、有约束、输入参数化（显式解）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;开环控制与闭环控制：MPC是优化开环有限时域控制问题，但是在每个采样时刻有状态反馈来补偿未建模动态和扰动。因此是闭环控制框架。&lt;/p&gt;

&lt;p&gt;MPC设计的选择：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;预测模型&lt;/li&gt;
&lt;li&gt;代价函数：范数、时域、终端代价&lt;/li&gt;
&lt;li&gt;约束：输入、状态约束、终端约束&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;软约束：用于克服不可行问题，在代价函数中惩罚约束违法，采用1范数或者无穷范数。通常用在不重要的约束，或者优先级排序。&lt;/p&gt;

&lt;h1 id=&#34;稳定性&#34;&gt;稳定性&lt;/h1&gt;

&lt;p&gt;稳定性的证明为两步法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;递归可行性（Recursive feasibility）controller well-defined for all k&lt;/li&gt;
&lt;li&gt;构造李雅普诺夫函数（trajectories converge to equilibrium）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;局限性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;only for ‘stabilization’ problems&lt;/li&gt;
&lt;li&gt;no general stability framework for ‘tracking’ problems&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Step1：recursive feasibility (terminal constraint)
假设没有模型失配！因此reusing the overlapping part of the input sequence will also result in an identical state sequence。&lt;/p&gt;

&lt;p&gt;三个条件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$X_N \subseteq X$ 保证移位后的倒数第二个状态满足状态约束&lt;/li&gt;
&lt;li&gt;$u(k+N|k+1)\in U$&lt;/li&gt;
&lt;li&gt;$x(k+N+1|k+1)\in X_N$ 终端不变集&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Step2：Lyapunov stability (terminal cost)&lt;/p&gt;

&lt;p&gt;如果存在 $V(x)$ 使得在0附近区域 $X_f$ 有 $V(x_{next})&amp;lt;V(x), V(0)=0$，则所有从$X_f$ 出发的轨迹能够渐进收敛到原点。&lt;/p&gt;

&lt;p&gt;在MPC框架下，$X_f$ 为可行域，$V(x)$为最优目标函数值。即&lt;/p&gt;

&lt;p&gt;$$
J(x(k+1),x_N^0(k+1),u_N^0(k+1))&amp;lt;J(x(k),x_N^0(k),u_N^0(k))
$$
条件4 (Lyapunov inequality)：
$$
F_N(x)-F_N(x,\kappa_N(x))\ge l(x,\kappa_N(x))
$$&lt;/p&gt;

&lt;p&gt;不变集：给定自治动态系统，如果当前状态在集合内，未来状态也都会在该集合内，则集合为正不变集。&lt;/p&gt;

&lt;p&gt;线性时不变系统的不变集：
给定 $x_{k+1}=\phi x_k,A_xx_k \le b_x$，则最大不变集可以通过&lt;/p&gt;

&lt;p&gt;$$
S = {x|A_xx\le b_x, A_x\phi x\le b_x,&amp;hellip;,A_x\phi^nx\le b_x }
$$
其中 $n$ 为一个有限的整数。$S$ 称为maximal admissible set。&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Set invariance in control. Automatica, 1999&lt;/li&gt;
&lt;li&gt;Constrained model predictive control: Stability and optimality. Automatica, 2000&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;鲁棒性&#34;&gt;鲁棒性&lt;/h1&gt;

&lt;p&gt;目的：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;保证递归可行性（考虑模型误差、扰动）&lt;/li&gt;
&lt;li&gt;保证渐近稳定性（在没有扰动的情况下）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;需要知道：
1. 模型不确定性的形式
2. 扰动的形式&lt;/p&gt;

&lt;h2 id=&#34;不确定性模型&#34;&gt;不确定性模型&lt;/h2&gt;

&lt;p&gt;线性参数变化模型&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;多胞不确定描述&lt;/li&gt;
&lt;li&gt;norm-bounded 不确定性描述&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;有界扰动&#34;&gt;有界扰动&lt;/h2&gt;

&lt;p&gt;通常为多面体（$W \in X$）：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$W=Co\{w_1,&amp;hellip;,w_n\}$&lt;/li&gt;
&lt;li&gt;$W=\{w|A_ww \le 1_v\}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;鲁棒MPC
需要进行的改造：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;不确定性预测&lt;/li&gt;
&lt;li&gt;终端代价需要满足 multiple Lyap. Ineq.&lt;/li&gt;
&lt;li&gt;终端约束需要是 a robust invariant set&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对状态预测树的所有节点添加约束&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>「系统辨识」再回首</title>
      <link>https://minghaochen.github.io/post/%E7%B3%BB%E7%BB%9F%E8%BE%A8%E8%AF%86%E5%86%8D%E5%9B%9E%E9%A6%96/</link>
      <pubDate>Sun, 01 Mar 2020 18:36:11 +0800</pubDate>
      
      <guid>https://minghaochen.github.io/post/%E7%B3%BB%E7%BB%9F%E8%BE%A8%E8%AF%86%E5%86%8D%E5%9B%9E%E9%A6%96/</guid>
      <description>&lt;p&gt;上一次学系统辨识已经两年多了，一直也都有在用，但是很多细节概念已经有些遗忘，现在再整体梳理一遍，方便自己也便于一些想入门系统辨识的小伙伴可以参考。&lt;/p&gt;

&lt;h1 id=&#34;系统辨识三要素&#34;&gt;系统辨识三要素&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;数据&lt;/li&gt;
&lt;li&gt;模型集（线性 or 非线性，连续 or 离散 等）：灰箱模型即结构已知（from physical law）参数带估计；黑箱模型即模型结构需要自己选择且参数没有物理意义&lt;/li&gt;
&lt;li&gt;准则：用于确定什么样的模型才是best的&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;模型验证&#34;&gt;模型验证&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;根据先验知识判断是否符合系统的物理特性，比如增益方向，时间常数等；&lt;/li&gt;
&lt;li&gt;根据未用于训练的实验数据进行验证，比较模型的仿真输出和实际观测输出。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;线性系统&#34;&gt;线性系统&lt;/h1&gt;

&lt;h2 id=&#34;线性回归&#34;&gt;线性回归&lt;/h2&gt;

&lt;p&gt;系统以线性回归表示为&lt;/p&gt;

&lt;p&gt;$$
y(k)=\phi^T(k)\theta
$$
其中 $\theta$ 为参数向量，$\phi(k)$ 为回归向量（通常包含过去时刻的输入输出值）。&lt;/p&gt;

&lt;p&gt;等价于&lt;/p&gt;

&lt;div&gt;$$
y(k)=G(q)u(k),G(q)=\frac{b_0+b_1q^{-1}+...+b_{nb}q^{-nb}}{1+a_1q^{-1}+...+a_{na}q^{-na}}
$$&lt;/div&gt;

&lt;p&gt;非线性系统也可以表示成线性回归的形式，比如在回归向量里包含 $y^2(k-1);u(k)y(k-1)$ 等。&lt;/p&gt;

&lt;h2 id=&#34;最小二乘估计&#34;&gt;最小二乘估计&lt;/h2&gt;

&lt;p&gt;定义残差（residuals）为 $\epsilon(k,\theta)=y(k)-\hat{y}(k,\theta)=y(k)-\phi^T(k)\theta$&lt;/p&gt;

&lt;p&gt;最小二乘估计即：&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}_{LS}=\arg \min_{\theta} \sum_{k=1}^{N} \epsilon^2(k,\theta)=\arg \min_{\theta} ||Y-\Phi \theta||^2
    $$
&lt;/div&gt;

&lt;p&gt;对 $\theta$ 求导，利用极值条件可以得到&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}_{LS}=(\Phi^T\Phi)^{-1}Y=(\sum_{k=1}^N \phi(k)\phi^T(k))^{-1} \sum_{k=1}^N \phi(k)y(k)
    $$
&lt;/div&gt;

&lt;p&gt;在 Matlab 里的实现就是&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}{LS} = \Phi \backslash Y
    $$
&lt;/div&gt;

&lt;p&gt;观察可以知道&lt;/p&gt;

&lt;div&gt;
    $$
    \Phi^T \Phi \hat{\theta}_{LS} = \Phi^T Y
    $$
&lt;/div&gt;

&lt;p&gt;利用 Cholesky 分解 $\Phi^T \Phi = LL^T$，其中 $L$ 是下三角矩阵，matlab代码 $L=chol(\Phi^T\Phi,&amp;lsquo;lower&amp;rsquo;)$&lt;/p&gt;

&lt;p&gt;因此最小二乘估计的解为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通过 forward substitution 求解 $Lz=\Phi^T Y$&lt;/li&gt;
&lt;li&gt;通过 backward substitution 求解 $L^T\hat{\theta}_{LS}=z$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;利用 QR 分解 $\Phi = QR=Q_1R_1$，其中 $Q=[Q_1,Q_2],R=[R_1,0]^T$，$Q_1^TQ=I$，$R_1$ 为上三角且当 $\Phi$ 满秩时 $R_1$ 对角线元素 $r_{ii}$ 大于0。matlab代码 $qr(\Phi)$。代入可得&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}_{LS}=(\Phi^T\Phi)^{-1}\Phi^TY=((Q_1R_1)^T(Q_1R_1))^{-1}(R_1^TQ_1^TY)=R_1^{-1}Q_1^TY
    $$
&lt;/div&gt;

&lt;p&gt;因此最小二乘估计的解为：&lt;/p&gt;

&lt;p&gt;通过 backward substitution 求解
$R_1\hat{\theta}_{LS} = Q_1^TY$&lt;/p&gt;

&lt;h2 id=&#34;recursive-线性最小二乘&#34;&gt;Recursive 线性最小二乘&lt;/h2&gt;

&lt;p&gt;可以对 $k-1$ 时刻的参数估计 $\hat{\theta}_{LS}(k-1)$ 进行更新得到 $\hat{\theta}_{LS}(k)$。&lt;/p&gt;

&lt;p&gt;定义 $P(k)=(\sum_{l=1}^k\phi(l)\phi^T(l))^{-1}$，满足 $P(k)^{-1}=P(k-1)^{-1}+\phi(k)\phi^T(k)$ 。&lt;/p&gt;

&lt;p&gt;强推一波公式，记住思路就是利用误差进行修正：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{\theta}_{LS}(k)&amp;=P(k)(\sum_{l=1}^{k-1}\phi(l)y(l) + \phi(k)y(k))\\
    &amp;=P(k)(P^{-1}(k-1)\hat{\theta}_{LS}(k-1)+\phi(k)y(k))\\
    &amp;=P(k)P^{-1}(k-1)\hat{\theta}_{LS}(k-1)+P(k)\phi(k)y(k)\\
    &amp;=P(k)(P(k)^{-1}-\phi(k)\phi^T(k))\hat{\theta}_{LS}(k-1)+P(k)\phi(k)y(k)\\
    &amp;=\hat{\theta}_{LS}(k-1) - P(k)\phi(k)\phi^T(k)\hat{\theta}_{LS}(k-1) +P(k)\phi(k)y(k)\\
    &amp;=\hat{\theta}_{LS}(k-1) + P(k)\phi(k)(y(k)-\phi^T(k)\hat{\theta}_{LS}(k-1))\\
    &amp;=\hat{\theta}_{LS}(k-1) + K(k)\epsilon(k)
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;其中 $K(k)=P(k)\phi(k)$ 可以看做是增益，$\epsilon(k)=y(k)-\phi^T(k)\hat{\theta}_{LS}(k-1)$ 看着是预测误差。&lt;/p&gt;

&lt;p&gt;因此 Recursive 线性最小二乘总结为：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{\theta}_{LS}(k) &amp;= \hat{\theta}_{LS}(k-1) + P(k)\phi(k)(y(k)-\phi^T(k)\hat{\theta}_{LS}(k-1))\\
    P(k)^{-1}&amp;=P(k-1)^{-1}+\phi(k)\phi^T(k)
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;由于矩阵涉及求逆费事，可以将 $P(k)^{-1}$ 转换为&lt;/p&gt;

&lt;div&gt;
    $$
    P(k)=P(k-1)+\frac{P(k-1)\phi(k)\phi^T(k)P(k-1)}{1+\phi^T(k)P(k-1)\phi(k)}
    $$
&lt;/div&gt;

&lt;h2 id=&#34;带遗忘因子的-recursive-线性最小二乘&#34;&gt;带遗忘因子的 Recursive 线性最小二乘&lt;/h2&gt;

&lt;p&gt;在目标函数引入遗忘因子 $0&amp;lt; \lambda \le 1$，即&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}=\arg \min_{\theta} \sum_{l=1}^k \lambda^{k-l}(y(l)-\phi^T(l)\theta)^2
    $$
&lt;/div&gt;

&lt;p&gt;$\lambda$ 越小对过去信息忘得越多。同理可以得到递推公式：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{\theta}_{LS}(k) &amp;= \hat{\theta}_{LS}(k-1) + P(k)\phi(k)(y(k)-\phi^T(k)\hat{\theta}_{LS}(k-1))\\
    P(k)&amp;=\frac{1}{\lambda} \left[ P(k-1)+\frac{P(k-1)\phi(k)\phi^T(k)P(k-1)}{\lambda+\phi^T(k)P(k-1)\phi(k)}\right]
    \end{aligned}
&lt;/div&gt;

&lt;h2 id=&#34;有限脉冲响应模型估计&#34;&gt;有限脉冲响应模型估计&lt;/h2&gt;

&lt;p&gt;利用 FIR 模型来描述系统的动态：&lt;/p&gt;

&lt;p&gt;$$
\hat{y}(k,g) = \sum_{l=0}^M g(l)u(k-l) = \phi^T(k)g
$$
其中 $\phi(k)=[u(k),u(k-1),&amp;hellip;,u(k-M)]^T,g=[g(0),&amp;hellip;,g(M)]^T$&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果 $M$ 足够大且系统 BIBO 稳定，FIR 模型能够很好近似原系统&lt;/li&gt;
&lt;li&gt;需要数据量 $N &amp;gt;&amp;gt; M$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最小二乘估计为 $\hat{g}=(\Phi^T\Phi)^{-1}\Phi^TY$&lt;/p&gt;

&lt;p&gt;假设真实系统可以被描述为&lt;/p&gt;

&lt;p&gt;$$
y(k)=\sum_{l=0}^M g_0(l)u(k-l)+v_0(k)=\phi^T(k
)g_0+v_0(k)
$$
其中 $v_0(k)$ 是零均值且与输入 $u$ 独立的准平稳噪声。&lt;/p&gt;

&lt;p&gt;一致性：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{g} &amp;= \left(\frac{1}{N}\sum_{l=1}^N \phi(k)\phi^T(k)\right)^{-1}\frac{1}{N}\sum_{k=1}^N\phi(k)y(k)\\
    &amp;=g_0 + \left(\frac{1}{N}\sum_{l=1}^N \phi(k)\phi^T(k)\right)^{-1}  \frac{1}{N}\sum_{l=1}^N \phi(k) v_0(k)\\
    &amp;=g_0 + R^*E[\phi(k)v_0(k)]\\
    &amp;=g_0
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;其中 $R$ 中每一项代表的是自相关或互相关函数的估计，$E[\phi(k)v_0(k)]=E[\phi(k)]\times 0=0$。&lt;/p&gt;

&lt;h2 id=&#34;arx-模型估计&#34;&gt;ARX 模型估计&lt;/h2&gt;

&lt;p&gt;模型结构为&lt;/p&gt;

&lt;div&gt;
    $$
    y(k)=\frac{B(q)}{A(q)}u(k)+\frac{1}{A(q)}e(k)
    $$
&lt;/div&gt;

&lt;p&gt;输入输出关系为：&lt;/p&gt;

&lt;div&gt;
    $$
    y(k)=-a_1y(k-1)-...-a_{n_a}y(k-n_a)+b_1u(k-1)+...+b_{n_b}u(k-n_b) + e(k)
    $$
&lt;/div&gt;

&lt;p&gt;同样可以写成线性回归的形式 $y(k)=\phi^T(k)\theta + e(k)$，同理得到最小二乘估计 $\hat{\theta}_{LS}=(\Phi^T\Phi)^{-1}\Phi^TY$。&lt;/p&gt;

&lt;p&gt;假设真实系统为 $y(k)=\phi^T(k)\theta_0+e(k)$，一致性检验可以得到 $lim_{N \rightarrow \infty} \hat{\theta}_{LS}=\theta_0 $&lt;/p&gt;

&lt;h2 id=&#34;线性参变-arx-模型估计&#34;&gt;线性参变 ARX 模型估计&lt;/h2&gt;

&lt;p&gt;模型描述&lt;/p&gt;

&lt;div&gt;
    $$
    y(k)=G(q^{-1},p(k))u(k)+v(k)
    $$
&lt;/div&gt;

&lt;p&gt;等价于&lt;/p&gt;

&lt;div&gt;
    $$
    A(q^{-1},p(k))y(k)=B(q^{-1},p(k))u(k)+e(k)
    $$
&lt;/div&gt;

&lt;p&gt;其中 $p$ 为调度变量。&lt;/p&gt;

&lt;p&gt;通常对回归向量的系数进行相应的参数化，比如多项式&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    A(q^{-1},p(k))=1+\sum_{i=1}^{n_a}a_i(p(k))q^{-i}\\
    a_i(p(k))=a_{i,0}+\sum_{l=1}^{n_l}a_{i,l}p^{l}(k)
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;div&gt;
    $$
    y(k)=-[a_{1,0}+a_{1,1}p(k)]y(k-1)+[b_{1,0}+b_{1,1}p(k)]u(k-1)+e(k)
    $$
&lt;/div&gt;

&lt;p&gt;此时有 $\phi^T(k)=[-y(k-1),-p(k)y(k-1),u(k-1),p(k)u(k-1)], \theta=[a&lt;em&gt;{1,0},a&lt;/em&gt;{1,1},b&lt;em&gt;{1,0},b&lt;/em&gt;{1,1}]^T$，同理还是利用最小二乘进行估计。当 $e(t)$ 为白噪声时，一致性能够得到保证。&lt;/p&gt;

&lt;h2 id=&#34;输出误差模型的不一致性&#34;&gt;输出误差模型的不一致性&lt;/h2&gt;

&lt;p&gt;模型结构&lt;/p&gt;

&lt;div&gt;
    $$
    y(k)=G(q)u(k)+H(q)e(k),H(q)=1
    $$
&lt;/div&gt;

&lt;p&gt;对应的输入输出关系&lt;/p&gt;

&lt;div&gt;
    $$
    y_0(k)=-a_1y_0(k-1)-...-a_{n_a}y_0(k-n_a)+b_1u(k-1)+...+b_{n_b}u(k-n_b)\\
    y(k)=y_0+e(k)
    $$
&lt;/div&gt;

&lt;p&gt;OE 模型则表示为&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    y(k)&amp;=\phi^T(k)\theta + e(k)+a_1e(k-1)+...a_{n_a}e(k-n_a)\\
    y(k)&amp;=\phi^T(k)\theta + v(k)
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;注意！这里 $v(k)$ 不是白噪声了！&lt;/p&gt;

&lt;p&gt;一致性：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{\theta}_{LS}&amp;=(\Phi^T\Phi)^{-1}\Phi^TY=\left(\frac{1}{N}\sum_{k=1}^N\phi(k)\phi^T(k) \right)^{-1}\frac{1}{N}\sum_{k=1}^N \phi(k)y(k)\\
    &amp;=\left(\frac{1}{N}\sum_{k=1}^N\phi(k)\phi^T(k) \right)^{-1}\frac{1}{N}\sum_{k=1}^N \phi(k) (\phi^T(k)\theta_0 + v(k)) \\
    &amp;=\theta_0 + \left(\frac{1}{N}\sum_{k=1}^N\phi(k)\phi^T(k) \right)^{-1}\frac{1}{N}\sum_{k=1}^N \phi(k) v(k)
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;由于 $\phi(k)$ 和 $v(k)$ 相关，所以 $lim_{N \rightarrow \infty} \frac{1}{N} \sum_{k=1}^N \phi(k)v(k) \neq 0$。&lt;/p&gt;

&lt;h2 id=&#34;辅助变量法&#34;&gt;辅助变量法&lt;/h2&gt;

&lt;p&gt;给定模型结构 $A(q^{-1}y(k))=B(q^{-1})u(k)+v(k)$，只有当 $v(k)$ 和回归向量不相关时，一致性才能得到保证。&lt;/p&gt;

&lt;p&gt;选择与回归向量 $\phi(k)$ 维度相同的辅助变量 $z(k)$ 使得&lt;/p&gt;

&lt;p&gt;$$
E[z(k)v(K)]=0
$$&lt;/p&gt;

&lt;p&gt;修正最小二乘估计为&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}_{IV}=(Z^T\Phi)^{-1}Z^TY=\left(\sum_{k=1}^N z(k)\phi^T(k) \right)^{-1}\sum_{k=1}^N z(k)y(k)
    $$
&lt;/div&gt;

&lt;p&gt;一致性：&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{\theta}_{IV}=\theta_0 + \left(\frac{1}{N}\sum_{k=1}^Nz(k)\phi^T(k) \right)^{-1}\frac{1}{N}\sum_{k=1}^N z(k) v(k)
    $$
&lt;/div&gt;

&lt;p&gt;因此 $z(k)$ 应该和 $\phi(k)$ 相关否则 $R(N)$ 会收敛到零矩阵。&lt;/p&gt;

&lt;p&gt;辅助变量的选择&lt;/p&gt;

&lt;div&gt;
    $$
    z(k)=[-y_0(k-1),...,-y_0(k-n_a),u(k-1),...,u(k-n_b)]^T
    $$
&lt;/div&gt;

&lt;p&gt;也就是说，$z(k)$ 应该尽可能和无噪的回归向量相关，但是和 $v(k)$ 无关。&lt;/p&gt;

&lt;p&gt;辅助变量法总结为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;最小二乘估计 $\hat{\theta}$ （biased）&lt;/li&gt;
&lt;li&gt;开环仿真
$$
\hat{y}(k)=[-\hat{y}(k-1),&amp;hellip;,-\hat{y}(k-n_a),u(k-1),&amp;hellip;,u(k-n_b)]^T\hat{\theta}
$$&lt;/li&gt;
&lt;li&gt;构造辅助变量
$$
z(k)=[-\hat{y}(k-1),&amp;hellip;,-\hat{y}(k-n_a),u(k-1),&amp;hellip;,u(k-n_b)]^T
$$&lt;/li&gt;
&lt;li&gt;通过 IV 估计 $\hat{\theta}$ （consistent）&lt;/li&gt;
&lt;li&gt;从第2步重复直到收敛&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;预报误差法-pem&#34;&gt;预报误差法 PEM&lt;/h1&gt;

&lt;p&gt;线性预报器&lt;/p&gt;

&lt;div&gt;
    $$
    \hat{y}(k|k-1;\theta) = L_y(q^{-1},\theta)y(k) + L_u(q^{-1},\theta) u(k); L_y(0,\theta)=0, L_u(0,\theta)=0  
    $$
&lt;/div&gt;

&lt;p&gt;只由过去的输入输出数据决定。&lt;/p&gt;

&lt;p&gt;预报误差为&lt;/p&gt;

&lt;p&gt;$$
\epsilon (k,\theta) = y(k)-\hat{y}(k|k-1,\theta)
$$&lt;/p&gt;

&lt;p&gt;待估计的参数应该使得预报误差尽可能小。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;模型结构，对 $G(q,\theta),H(q,\theta)$ 的参数化；&lt;/li&gt;
&lt;li&gt;预报器，定义 $L_y,L_u$；&lt;/li&gt;
&lt;li&gt;准则，预报误差的 scalar 函数 $V_N(\theta)$；&lt;/li&gt;
&lt;li&gt;估计 $\hat{\theta}=\arg \min_{\theta} V_N(\theta)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;单变量模型结构&#34;&gt;单变量模型结构&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ARX
$$y(k)=\frac{B(q,\theta)}{A(q,\theta)}u(k)+\frac{1}{A(q,\theta)}e(k)$$&lt;/li&gt;
&lt;li&gt;ARMAX
$$y(k)=\frac{B(q,\theta)}{A(q,\theta)}u(k)+\frac{C(q,\theta)}{A(q,\theta)}e(k)$$&lt;/li&gt;
&lt;li&gt;OE
$$y(k)=\frac{B(q,\theta)}{A(q,\theta)}u(k)+e(k)$$&lt;/li&gt;
&lt;li&gt;BJ
$$y(k)=\frac{B(q,\theta)}{A(q,\theta)}u(k)+\frac{C(q,\theta)}{D(q,\theta)}e(k)$$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;预报滤波器&#34;&gt;预报滤波器&lt;/h2&gt;

&lt;p&gt;应该选择滤波器 $L_y,L_u$ 使得预报误差的方差最小。&lt;/p&gt;

&lt;div&gt;
\begin{aligned}
y(k)&amp;=Gu(k)+He(k)=Gu(k)+(H-I)e(k)+e(k)\\
    &amp;=Gu(k)+(H-I)H^{-1}[y(k)-Gu(k)]+e(k)\\
    &amp;=[(I-H^{-1})y(k)+H^{-1}Gu(k)]+e(k)\\
    &amp;=z(k)+e(k)
\end{aligned}
&lt;/div&gt;

&lt;p&gt;注意 $z(k),e(k)$ 不相关。&lt;/p&gt;

&lt;p&gt;假设 $y^*(k)$ 为 $y(k)$ 的任意预测，$z(k)$ 的最优性：&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    E[(y-y^*)(y-y^*)^T]&amp;=E[(z+e-y^*)(z+e-y^*)^T]\\
    &amp;=E[(z-y^*)(z-y^*)^T]+E[ee^T] \ge \Lambda_e
    \end{aligned}
&lt;/div&gt;

&lt;p&gt;因此 $z(k)$ 是最优预报，$e(k)$ 是最优预报误差。&lt;/p&gt;

&lt;div&gt;
    \begin{aligned}
    \hat{y}(k|k-1,\theta)&amp;=\left(I-H^{-1}(q^{-1},\theta)\right)y(k)+H^{-1}(q^{-1},\theta)G(q^{-1},\theta)u(k)\\
    \epsilon (k,\theta)&amp;=e(k)=H^{-1}(q^{-1},\theta)\left(y(k)-G(q^{-1},\theta)u(k)\right)
    \end{aligned}
&lt;/div&gt;

&lt;h2 id=&#34;最小化准则&#34;&gt;最小化准则&lt;/h2&gt;

&lt;p&gt;采样协方差矩阵&lt;/p&gt;

&lt;div&gt;
    $$
    R_N(\theta)=\frac{1}{N}\sum_{k=1}^N \epsilon(k,\theta)\epsilon^T(k,\theta)
    $$
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;如果 $y$ 是标量，$R_N(\theta)$ 可以直接作为 $V_N(\theta)$ 用于最小化。&lt;/li&gt;
&lt;li&gt;如果是多变量，我们可以最小化
$$
V_N(\theta)=h(R_N(\theta))
$$
其中，$h$ 为定义在正半定矩阵集合上的连续的单调递增函数满足 $h(Q+\Delta Q)\ge h(Q),\forall Q,\Delta Q \ge 0$，比如矩阵的迹 $V_N(\theta)=h(R_N(\theta))=tr(R_N(\theta))$。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>