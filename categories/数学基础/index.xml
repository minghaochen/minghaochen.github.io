<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数学基础 on MH&#39;s Blog</title>
    <link>https://minghaochen.github.io/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</link>
    <description>Recent content in 数学基础 on MH&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>MinghaoChen</copyright>
    <lastBuildDate>Thu, 25 Jul 2019 15:27:09 +0800</lastBuildDate>
    
	<atom:link href="https://minghaochen.github.io/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Chol分解与SVD分解</title>
      <link>https://minghaochen.github.io/post/chol%E5%88%86%E8%A7%A3%E4%B8%8Esvd%E5%88%86%E8%A7%A3/</link>
      <pubDate>Thu, 25 Jul 2019 15:27:09 +0800</pubDate>
      
      <guid>https://minghaochen.github.io/post/chol%E5%88%86%E8%A7%A3%E4%B8%8Esvd%E5%88%86%E8%A7%A3/</guid>
      <description>&lt;p&gt;今天说说两个整天见却整天忘的矩阵分解，一个是Chol分解，一个是SVD分解&lt;/p&gt;

&lt;h1 id=&#34;chol分解&#34;&gt;Chol分解&lt;/h1&gt;

&lt;p&gt;对于Chol分解，首先要知道它针对的对象是什么，也就是&lt;strong&gt;埃尔米特矩阵（Hermitian matrix）&lt;/strong&gt;，听着有点难懂，其实就是共轭对称矩阵，再简单点说，我们常见的实对称矩阵就是埃尔米特矩阵的特例。&lt;/p&gt;

&lt;p&gt;那么这个Chol分解分解得到的是什么东西？是干嘛用的呢？
我们先来回答第一个问题，Chol分解是将一个矩阵分解成两个矩阵的乘积，即
$$
A = LL^*
$$
其中，$L$ 是一个&lt;strong&gt;下三角&lt;/strong&gt;矩阵，$L^*$ 是 $L$ 的共轭转置，如果实数那就是转置（i.e., $L^T$）&lt;/p&gt;

&lt;p&gt;分解成这个玩意干嘛用的呢？目前了解到的比较常用的两个地方&lt;/p&gt;

&lt;h2 id=&#34;1-解线性方程呗-比如-ax-b&#34;&gt;1. 解线性方程呗，比如 $Ax=b$&lt;/h2&gt;

&lt;p&gt;你可能会说直接目测方程的解就是 $x = A^{-1}b$，还需要什么Chol分解？如果矩阵 $A$ 是病态的（条件数很大），那么问题就来了，我们在用计算机求解这类问题的时候出现舍入误差可能会导致所答非所问。&lt;/p&gt;

&lt;p&gt;如果对矩阵进行Chol分解再来求解方程呢，原方程需要两步求解&lt;/p&gt;

&lt;p&gt;Step1
$$
Ly=b
$$
Step2
$$
L^Tx=y
$$
打开Matlab感受一下？&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;A = [5,7;7,10];
cond(A)
L = chol(A)&amp;#39;;
cond(L)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;可以看出分解后求解的两个方程都是良态的且只需储存矩阵的下三角部分即可咯。&lt;/p&gt;

&lt;h2 id=&#34;2-求矩阵的行列式&#34;&gt;2. 求矩阵的行列式&lt;/h2&gt;

&lt;p&gt;既然Chol分解把矩阵分解成下三角阵，那么求解原矩阵的行列式自然非常容易了&lt;/p&gt;

&lt;div&gt;$$
\begin{aligned} \operatorname{det} {A} &amp;=\prod_{i=1}^{n} {L}_{i i}^{2} \\ \log \operatorname{det} {A} &amp;=2 \sum_{i=1}^{n} \log {L}_{i i} \end{aligned}
$$&lt;/div&gt;

&lt;p&gt;其中 ${L}_{i i}$ 为矩阵的对角元素。&lt;/p&gt;

&lt;h1 id=&#34;svd分解&#34;&gt;SVD分解&lt;/h1&gt;

&lt;p&gt;要说SVD分解，首先要提到特征根分解，线代学过吧？忘记了没关系，我们再来复习一下。&lt;/p&gt;

&lt;p&gt;首先还是要知道特征值分解的对象是什么，答案是&lt;strong&gt;方阵&lt;/strong&gt;，对于方阵 $A$，有&lt;/p&gt;

&lt;p&gt;$$
Av=\lambda v
$$&lt;/p&gt;

&lt;p&gt;这时，$v$ 就称为特征向量，$\lambda$ 就是与之对应的特征值。&lt;/p&gt;

&lt;p&gt;那么这个特征值分解分解得到的是什么东西？是干嘛用的呢？&lt;/p&gt;

&lt;p&gt;通过特征值分解，可以把矩阵 $A$ 分解为&lt;/p&gt;

&lt;p&gt;$$
A = Q\Sigma Q^{-1}
$$&lt;/p&gt;

&lt;p&gt;其中 $Q$ 就是特征向量组成的矩阵，$\Sigma$ 就是对角线为对应特征值的对角阵。&lt;/p&gt;

&lt;p&gt;这样分解有什么用呢？我们知道矩阵的本质就是线性变换，那么分解后我不就知道&lt;strong&gt;变换方向的主次&lt;/strong&gt;了，因为我们分解得到的 $\Sigma$ 是一个对角阵且特征值从大到小排列，而特征值所对应的特征向量也就是描述矩阵的变化方向，所以 $Q$ 矩阵就是&lt;strong&gt;按照主要变化到次要变化进行排列&lt;/strong&gt;。那么我们就可以根据自己的需要选择特定个数的变化方向来近似原始矩阵变化，也就是&lt;strong&gt;提取原始矩阵中我们期望的主要特征&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;那么这些和今天的猪脚SVD有什么联系呢？（哪有猪脚，肚肚饿）&lt;/p&gt;

&lt;p&gt;关系可大了，你可以粗糙地把SVD也当做是特征值分解，虽然不太准确。上面说到特征值分解针对的是&lt;strong&gt;方阵&lt;/strong&gt;，可是哪来那么多的方阵啊！遇到非方阵时特征值分解不就GG了，这时候SVD出场了。&lt;/p&gt;

&lt;p&gt;一句话概括SVD是适用&lt;strong&gt;任意&lt;/strong&gt;，是&lt;strong&gt;任意&lt;/strong&gt;矩阵的一种分解方法：&lt;/p&gt;

&lt;p&gt;&lt;div&gt;$$
A_{m \times n} = U_{m \times m} \Sigma_{m \times n}V_{n \times n}^T
$$&lt;div&gt;&lt;/p&gt;

&lt;p&gt;那么奇异值和特征值是怎么对应起来的呢？由于矩阵 $A$ 不一定是方阵，我们乘以它的转置就能得到方阵，那么就能特征值分解了。&lt;/p&gt;

&lt;p&gt;$$
(A^TA)v_i = \lambda_iv_i
$$&lt;/p&gt;

&lt;p&gt;这样求得的 $v_i$ 就组成了SVD中的右奇异矩阵 $V$，此外&lt;/p&gt;

&lt;p&gt;$$
\sigma_i=\sqrt{\lambda_i},u_i=Av_i/\sigma_i
$$&lt;/p&gt;

&lt;p&gt;这里的 $\sigma_i$ 就是所谓的奇异值，它在矩阵 $\Sigma$ 中也是从大到小排列的，而且&lt;strong&gt;减小速度非常快！&lt;/strong&gt;，这可是个好消息，说明我们利用&lt;strong&gt;很少的奇异值就能近似描述原始矩阵&lt;/strong&gt;，相当于是&lt;strong&gt;空间压缩&lt;/strong&gt;，比如我们利用 $r$ 个奇异值来近似原始矩阵（$r$ 远小于 $m$ 或 $n$）&lt;/p&gt;

&lt;p&gt;$$
A_{m \times n} = U_{m \times r} \Sigma_{r \times r}V_{r \times n}^T
$$&lt;/p&gt;

&lt;p&gt;所以总的来说SVD就是用来提取重要特征的一个方法。SVD或者特征值分解的具体实现都有现成的函数可以调用，感兴趣可以通过matlab分解一把再观察一下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[Q,Sigma1] = eig(A&amp;#39;*A)   % matlab求特征值不一定按从小到大排序的 
[U,Sigma2,V] = svd(A)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;观察一下 $Q$ 和 $V$ 的关系以及 $Sigma1$ 和 $Sigma2$ 的关系，可以再根据上面给出的公式人工计算一下 $U$ 矩阵，再和matlab的结果进行比较。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>